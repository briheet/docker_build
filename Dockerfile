# syntax=docker/dockerfile:1.7
# Generated by cozyctl
# Configuration: Python 3.11 + PyTorch + CUDA 12.6
FROM ghcr.io/astral-sh/uv:python3.11-bookworm-slim AS cozy_base

WORKDIR /app

ENV UV_CACHE_DIR=/var/cache/uv
ENV UV_LINK_MODE=copy
ENV UV_HTTP_TIMEOUT=300

# Git is required for direct VCS dependencies (e.g. diffusers @ git+...).
RUN --mount=type=cache,id=cozy-apt-cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,id=cozy-apt-lists,target=/var/lib/apt/lists,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    git \
    && apt-get clean

# Install stable shared runtime layers first for better cache reuse.
RUN --mount=type=cache,id=cozy-uv-cache,target=/var/cache/uv,sharing=locked \
    uv pip install --system --break-system-packages --torch-backend cu126 \
    "torch~=2.5"

# Optional dev/e2e overlay: publish-dir can vendor a local copy of gen-worker under
# .cozy/vendor/gen-worker so worker images include unreleased runtime changes.
#
# Important: keep this AFTER torch install so torch layers stay cacheable across
# frequent gen-worker edits (big win for rebuild + runtime image pull speed).
COPY .cozy/vendor/gen-worker /opt/gen-worker

RUN --mount=type=cache,id=cozy-uv-cache,target=/var/cache/uv,sharing=locked \
    if [ -f /opt/gen-worker/pyproject.toml ]; then \
      uv pip install --system --break-system-packages /opt/gen-worker; \
    else \
      uv pip install --system --break-system-packages "gen-worker==0.2.1"; \
    fi
RUN --mount=type=cache,id=cozy-uv-cache,target=/var/cache/uv,sharing=locked \
    # Keep these as explicit shared-layer deps. They are excluded from project installs
    # when the tenant depends on gen-worker[torch], because we install gen-worker
    # separately to prevent torch replacement.
    uv pip install --system --break-system-packages \
      "safetensors>=0.7.0" \
      "flashpack>=0.2.1" \
      "numpy>=2.4.2"

# Final stage: app-specific deps + code.
FROM cozy_base

# Copy lock metadata first so dependency layers are cacheable across releases.
# We install dependencies from the lock, then install the project itself with --no-deps.
COPY pyproject.toml uv.lock ./

# Install Python dependencies into global site-packages (no project venv).
# Important:
# - --no-sources ignores tool.uv.sources so uploaded tarballs don't need local path deps.
# - We exclude torch + gen-worker because those are installed by the builder earlier and
#   must never be replaced by project requirements.
RUN --mount=type=cache,id=cozy-uv-cache,target=/var/cache/uv,sharing=locked \
    uv export --locked --no-dev --no-hashes --no-sources --no-emit-project \
      --no-emit-package torch --no-emit-package gen-worker \
      -o /tmp/requirements.all.txt \
    # If the project lock includes torch deps (often via accelerate), never install them here.
    # Torch is installed in a stable layer above via --torch-backend (or omitted for CPU images).
    && grep -Ev '^(torch|triton|nvidia-|cuda-)' /tmp/requirements.all.txt > /tmp/requirements.txt \
    && uv pip install --system --break-system-packages --no-deps -r /tmp/requirements.txt

# Copy application code late so app edits only invalidate the final layers.
COPY . .

# Install the project itself without altering dependency layers.
RUN --mount=type=cache,id=cozy-uv-cache,target=/var/cache/uv,sharing=locked \
    uv pip install --system --break-system-packages --no-deps --no-sources /app

# Set USER_MODULES so discover finds the worker functions
ENV USER_MODULES=worker

# Generate function manifest at build time.
# Backward-compat: published gen-worker currently exposes ModelRefSource.DEPLOYMENT.
RUN mkdir -p /app/.cozy && python -c 'from gen_worker.injection import ModelRefSource as M; import runpy; hasattr(M, "RELEASE") or setattr(M, "RELEASE", M.DEPLOYMENT); runpy.run_module("gen_worker.discover", run_name="__main__")' > /app/.cozy/manifest.json

# Run as non-root at runtime.
RUN groupadd --system --gid 10001 cozy \
    && useradd --system --uid 10001 --gid cozy --create-home --home-dir /home/cozy --shell /usr/sbin/nologin cozy \
    && chown -R cozy:cozy /app /home/cozy

# Set environment variables
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
ENV HOME=/home/cozy
ENV XDG_CACHE_HOME=/home/cozy/.cache
ENV HF_HOME=/home/cozy/.cache/huggingface
ENV COZY_DEPLOYMENT_ID="sdxl-turbo-test"
ENV HF_HOME="/app/.cache/huggingface"

USER cozy:cozy

# Default command - runs gen-worker entrypoint
CMD ["python", "-m", "gen_worker.entrypoint"]
